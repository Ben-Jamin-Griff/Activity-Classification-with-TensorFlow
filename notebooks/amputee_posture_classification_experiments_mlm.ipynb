{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "amputee_posture_classification_experiments_mlm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGDPgZ-v1a9z"
      },
      "source": [
        "# FUNCTIONS\n",
        "\n",
        "#ActivityCodes (0=sedentary 1=standing 2=stepping 2.1=cycling 3.1=primary lying, 3.2=secondary lying 4=non-wear 5=travelling)\n",
        "def reassign_classes(classes):\n",
        "  for count, value in enumerate(classes):\n",
        "    if classes[count] == 2.1:\n",
        "      classes[count] = 2\n",
        "    elif classes[count] == 3.1:\n",
        "      classes[count] = 3\n",
        "    elif classes[count] == 3.2:\n",
        "      classes[count] = 3\n",
        "    elif classes[count] == 5.0:\n",
        "      classes[count] = 0\n",
        "    else:\n",
        "      continue\n",
        "  return classes\n",
        "\n",
        "# Removing non-wear because it destroys the NN\n",
        "def remove_classes(dataset, stack, class_to_remove):\n",
        "  remove_non_wear_idx = posture_classes != class_to_remove\n",
        "  stack = stack[remove_non_wear_idx]\n",
        "  dataset = dataset[remove_non_wear_idx]\n",
        "  return dataset, stack\n",
        "\n",
        "# Reshape the data for specific models\n",
        "def reshape_set(dataset, new_shape):\n",
        "  shaper = dataset.shape\n",
        "  new_shape.insert(0, shaper[0])\n",
        "  new_shape = tuple(new_shape)\n",
        "  dataset = dataset.reshape(new_shape)\n",
        "  return dataset\n",
        "\n",
        "def one_hot_data(stack):\n",
        "  unique_classes = np.unique(stack)\n",
        "  stack = tf.one_hot(stack, len(unique_classes))\n",
        "  return stack\n",
        "\n",
        "def review_class_imbalance(y_train, y_test, labels=None):\n",
        "  # Find the unique label values...\n",
        "  unique_classes_train = np.unique(y_train)\n",
        "  unique_classes_test = np.unique(y_test)\n",
        "  # Count the unique label values\n",
        "  unique_train, counts_train = np.unique(y_train, return_counts=True)\n",
        "  unique_test, counts_test = np.unique(y_test, return_counts=True)\n",
        "  try:\n",
        "    count_class_values_train = dict(zip(labels, counts_train))\n",
        "    count_class_values_test = dict(zip(labels, counts_test))\n",
        "  except:\n",
        "    count_class_values_train = dict(zip(unique_train, counts_train))\n",
        "    count_class_values_test = dict(zip(unique_test, counts_test))\n",
        "\n",
        "  print('Train Classes')\n",
        "  print(count_class_values_train)\n",
        "  print('--------------')\n",
        "  print('Test Classes')\n",
        "  print(count_class_values_test)\n",
        "  print('--------------')\n",
        "  return unique_classes_train, unique_classes_test\n",
        "\n",
        "def norm_accel_data(x):\n",
        "  \"\"\"\n",
        "  Processes accel values and returns a normalised integer (0-1).\n",
        "  \"\"\"\n",
        "  x_minimum = 0\n",
        "  x_maximum = 255\n",
        "  x_normalized = ((x - x_minimum) / (x_maximum - x_minimum))\n",
        "  return x_normalized\n",
        "\n",
        "def process_epochs(x, y=None, shuffle=False):\n",
        "  \"\"\"\n",
        "  Processing epochs\n",
        "  \"\"\"\n",
        "  print(\"Creating training data...\")\n",
        "  # Normalize the acceleration data\n",
        "  x = norm_accel_data(x)\n",
        "  # Convert data to a tensor\n",
        "  data = tf.constant(x)\n",
        "  # If the data is a training dataset, we shuffle it\n",
        "  if shuffle:\n",
        "    indices = tf.range(start=0, limit=tf.shape(data)[0], dtype=tf.int32)\n",
        "    shuffled_indices = tf.random.shuffle(indices)\n",
        "    shuffled_x = tf.gather(x, shuffled_indices)\n",
        "    shuffled_y = tf.gather(y, shuffled_indices)\n",
        "    return shuffled_x, shuffled_y\n",
        "  else:\n",
        "    return data\n",
        "\n",
        "def show_confusion_matrix(validations, predictions):\n",
        "    matrix = metrics.confusion_matrix(validations, predictions, normalize ='true')\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(matrix,\n",
        "                cmap='coolwarm',\n",
        "                linecolor='white',\n",
        "                linewidths=1,\n",
        "                xticklabels=LABELS,\n",
        "                yticklabels=LABELS,\n",
        "                annot=True)\n",
        "                #fmt='d')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.show()\n",
        "\n",
        "def show_training(history):\n",
        "  # summarize history for accuracy\n",
        "  plt.figure(figsize=(10, 4))\n",
        "  plt.plot(history.history['accuracy'])\n",
        "  plt.plot(history.history['val_accuracy'])\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'test'], loc='upper left')\n",
        "  plt.show()\n",
        "  # summarize history for loss\n",
        "  plt.figure(figsize=(10, 4))\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'validation'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "def show_model_results(model_to_test, data_to_test, validation):\n",
        "  predictions = model_to_test.predict(data_to_test)\n",
        "  predictions_max = np.argmax(predictions, axis=1)\n",
        "\n",
        "  show_confusion_matrix(validation, predictions_max)\n",
        "  print('------------')\n",
        "  print(classification_report(validation, predictions_max))\n",
        "\n",
        "def train_and_save_model(model_to_train, X_train, y_train, model_name):\n",
        "\n",
        "  #callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10)\n",
        "\n",
        "  # Hyper-parameters\n",
        "  EPOCHS = 50\n",
        "\n",
        "  model_to_train.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "  \n",
        "  history = model_to_train.fit(X_train,\n",
        "                  y_train,\n",
        "                  epochs=EPOCHS,\n",
        "                  validation_split=0.2,\n",
        "                  batch_size=32,\n",
        "                  #callbacks=[callback],\n",
        "                  verbose=1)\n",
        "\n",
        "  show_training(history)\n",
        "\n",
        "  filename  = '/content/drive/MyDrive/Documents/Work/UOS Post-Doc/Amputee Posture Classification/models/' + model_name + '.h5'\n",
        "\n",
        "  # save the model\n",
        "  model_to_train.save(filename)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4d_XPIiz6yz",
        "outputId": "3114ac0c-0c2a-46ed-bc02-a09e269a5df6"
      },
      "source": [
        "!pip install pyyaml h5py\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "print(\"TF version:\", tf.__version__)\n",
        "\n",
        "# Import more tools\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import sklearn.metrics as metrics\n",
        "\n",
        "# Check for GPU availability\n",
        "print(\"GPU\", \"available ðŸ¤—\" if tf.config.list_physical_devices(\"GPU\") else \"not available ðŸ˜Ÿ\")\n",
        "\n",
        "print('------------')\n",
        "\n",
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py) (1.15.0)\n",
            "TF version: 2.4.1\n",
            "GPU available ðŸ¤—\n",
            "------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[name: \"/device:CPU:0\"\n",
              " device_type: \"CPU\"\n",
              " memory_limit: 268435456\n",
              " locality {\n",
              " }\n",
              " incarnation: 9291396848035930299, name: \"/device:GPU:0\"\n",
              " device_type: \"GPU\"\n",
              " memory_limit: 14674281152\n",
              " locality {\n",
              "   bus_id: 1\n",
              "   links {\n",
              "   }\n",
              " }\n",
              " incarnation: 5003797569849956474\n",
              " physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UxdiFb_1Xj_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac543f5a-6787-4161-bcc1-878127b3d205"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "engineering_set1 = np.load('/content/drive/MyDrive/Documents/Work/UOS Post-Doc/Amputee Posture Classification/data/1_pure_engineering_set.npy')\n",
        "posture_classes1 = np.load('/content/drive/MyDrive/Documents/Work/UOS Post-Doc/Amputee Posture Classification/data/1_pure_engineering_set_classes.npy')\n",
        "engineering_set2 = np.load('/content/drive/MyDrive/Documents/Work/UOS Post-Doc/Amputee Posture Classification/data/2_pure_engineering_set.npy')\n",
        "posture_classes2 = np.load('/content/drive/MyDrive/Documents/Work/UOS Post-Doc/Amputee Posture Classification/data/2_pure_engineering_set_classes.npy')\n",
        "engineering_set3 = np.load('/content/drive/MyDrive/Documents/Work/UOS Post-Doc/Amputee Posture Classification/data/3_pure_engineering_set.npy')\n",
        "posture_classes3 = np.load('/content/drive/MyDrive/Documents/Work/UOS Post-Doc/Amputee Posture Classification/data/3_pure_engineering_set_classes.npy')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0IstaLc38jZ"
      },
      "source": [
        "engineering_set = np.concatenate((engineering_set1, engineering_set2, engineering_set3), axis=0)\n",
        "posture_classes = np.concatenate((posture_classes1, posture_classes2, posture_classes3), axis=0)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbkP4GoqBLSh",
        "outputId": "2cdf47dc-fed0-4f3b-834d-2e53f3248178"
      },
      "source": [
        "# Main Processing\n",
        "posture_classes = reassign_classes(posture_classes)\n",
        "engineering_set, posture_classes = remove_classes(engineering_set, posture_classes, 4)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(engineering_set, posture_classes, test_size=0.2, random_state=42)\n",
        "\n",
        "y_train_hot = one_hot_data(y_train)\n",
        "y_test_hot = one_hot_data(y_test)\n",
        "\n",
        "X_train_reshaped1 = reshape_set(X_train, [1,5,59,3])\n",
        "X_test_reshaped1 = reshape_set(X_test, [1,5,59,3])\n",
        "\n",
        "X_train_reshaped2 = reshape_set(X_train, [5,1,59,3])\n",
        "X_test_reshaped2 = reshape_set(X_test, [5,1,59,3])\n",
        "\n",
        "X_train = process_epochs(X_train)\n",
        "X_test = process_epochs(X_test)\n",
        "\n",
        "X_train_reshaped1 = process_epochs(X_train_reshaped1)\n",
        "X_test_reshaped1 = process_epochs(X_test_reshaped1)\n",
        "\n",
        "X_train_reshaped2 = process_epochs(X_train_reshaped2)\n",
        "X_test_reshaped2 = process_epochs(X_test_reshaped2)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating training data...\n",
            "Creating training data...\n",
            "Creating training data...\n",
            "Creating training data...\n",
            "Creating training data...\n",
            "Creating training data...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-Dwa4XHxRU9",
        "outputId": "0fe0b26a-ae41-4706-d0c9-3115e813b7e5"
      },
      "source": [
        "LABELS = ['Sedentary', 'Standing', 'Stepping', 'Lying']\n",
        "\n",
        "unique_classes_train, unique_classes_test = review_class_imbalance(y_train, y_test, LABELS)\n",
        "\n",
        "INPUT_SHAPE = X_train.shape[1:]\n",
        "print('input shape:', INPUT_SHAPE)\n",
        "\n",
        "INPUT_SHAPE_RESHAPED_1 = X_train_reshaped1.shape[1:]\n",
        "print('input shape reshaped:', INPUT_SHAPE_RESHAPED_1)\n",
        "\n",
        "INPUT_SHAPE_RESHAPED_2 = X_train_reshaped2.shape[1:]\n",
        "print('input shape reshaped:', INPUT_SHAPE_RESHAPED_2)\n",
        "\n",
        "OUTPUT_SHAPE = len(unique_classes_train)\n",
        "print('output shape:', OUTPUT_SHAPE)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Classes\n",
            "{'Sedentary': 54798, 'Standing': 35903, 'Stepping': 11478, 'Lying': 54909}\n",
            "--------------\n",
            "Test Classes\n",
            "{'Sedentary': 13744, 'Standing': 8982, 'Stepping': 2876, 'Lying': 13670}\n",
            "--------------\n",
            "input shape: (295, 3)\n",
            "input shape reshaped: (1, 5, 59, 3)\n",
            "input shape reshaped: (5, 1, 59, 3)\n",
            "output shape: 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0JQYzdNVQM4"
      },
      "source": [
        "# Models from - https://machinelearningmastery.com/how-to-develop-rnn-models-for-human-activity-recognition-time-series-classification/\n",
        "\n",
        "mlm_lstm_model = tf.keras.Sequential([\n",
        "                                      tf.keras.layers.LSTM(100, input_shape=INPUT_SHAPE),\n",
        "                                      tf.keras.layers.Dropout(0.5),\n",
        "                                      tf.keras.layers.Dense(100, activation='relu'),\n",
        "                                      tf.keras.layers.Dense(OUTPUT_SHAPE, activation='softmax')],\n",
        "                                      name='MLM-LSTM-Model')\n",
        "\n",
        "mlm_cnn_lstm_model = tf.keras.Sequential([\n",
        "                                          tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu'), input_shape=INPUT_SHAPE_RESHAPED_1),\n",
        "                                          tf.keras.layers.TimeDistributed(tf.keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu')),\n",
        "                                          tf.keras.layers.TimeDistributed(tf.keras.layers.Dropout(0.5)),\n",
        "                                          tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPooling2D(pool_size=2)),\n",
        "                                          tf.keras.layers.TimeDistributed(tf.keras.layers.Flatten()),\n",
        "                                          tf.keras.layers.LSTM(100),\n",
        "                                          tf.keras.layers.Dropout(0.5),\n",
        "                                          tf.keras.layers.Dense(100, activation='relu'),\n",
        "                                          tf.keras.layers.Dense(OUTPUT_SHAPE, activation='softmax')],\n",
        "                                          name='MLM-CNN-LSTM-Model')\n",
        "\n",
        "mlm_convlstm_model = tf.keras.Sequential([\n",
        "                                          tf.keras.layers.ConvLSTM2D(filters=64, kernel_size=(1,3), activation='relu', input_shape=INPUT_SHAPE_RESHAPED_2),\n",
        "                                          tf.keras.layers.Dropout(0.5),\n",
        "                                          tf.keras.layers.Flatten(),\n",
        "                                          tf.keras.layers.Dense(100, activation='relu'),\n",
        "                                          tf.keras.layers.Dense(OUTPUT_SHAPE, activation='softmax')],\n",
        "                                          name='MLM-ConvLSTM-Model')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6UqXEvvSqtI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92020cae-903b-49db-c768-0ad46228f8ae"
      },
      "source": [
        "# Training and saving the models\n",
        "\n",
        "#train_and_save_model(mlm_lstm_model, X_train, y_train_hot, 'mlm_lstm_model')\n",
        "train_and_save_model(mlm_cnn_lstm_model, X_train_reshaped1, y_train_hot, 'mlm_cnn_lstm_model')\n",
        "#train_and_save_model(mlm_convlstm_model, X_train_reshaped2, y_train_hot, 'mlm_convlstm_model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqVswptDfYqm"
      },
      "source": [
        "valid = np.argmax(y_test_hot, axis=1)\n",
        "\n",
        "# ---------- LSTM Model ----------\n",
        "#mlm_lstm_model_loaded = tf.keras.models.load_model('/content/drive/MyDrive/Documents/Work/UOS Post-Doc/Amputee Posture Classification/models/mlm_lstm_model.h5')\n",
        "#mlm_lstm_model_loaded.summary()\n",
        "#show_model_results(mlm_lstm_model_loaded, X_test, valid)\n",
        "\n",
        "print('------------------------------------------------------------------------------------------------')\n",
        "\n",
        "# ---------- CNN LSTM Model ----------\n",
        "mlm_cnn_lstm_model_loaded = tf.keras.models.load_model('/content/drive/MyDrive/Documents/Work/UOS Post-Doc/Amputee Posture Classification/models/mlm_cnn_lstm_model.h5')\n",
        "mlm_cnn_lstm_model_loaded.summary()\n",
        "show_model_results(mlm_cnn_lstm_model_loaded, X_test_reshaped1, valid)\n",
        "\n",
        "print('------------------------------------------------------------------------------------------------')\n",
        "\n",
        "# ---------- Conv LSTM Model ----------\n",
        "#mlm_convlstm_model_loaded = tf.keras.models.load_model('/content/drive/MyDrive/Documents/Work/UOS Post-Doc/Amputee Posture Classification/models/mlm_convlstm_model.h5')\n",
        "#mlm_convlstm_model_loaded.summary()\n",
        "#show_model_results(mlm_convlstm_model_loaded, X_test_reshaped2, valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTIrplDAD0SC"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}